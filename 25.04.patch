diff --git a/setup.py b/setup.py
index 4aa6616..71cef59 100644
--- a/setup.py
+++ b/setup.py
@@ -87,15 +87,15 @@ if not torch.cuda.is_available():
     if os.environ.get("TORCH_CUDA_ARCH_LIST", None) is None and CUDA_HOME is not None:
         _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)
         if bare_metal_version >= Version("12.8"):
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "7.0;7.5;8.0;8.6;9.0;10.0;12.0"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "7.0;7.5;8.0;8.6;9.0;10.0;12.0+PTX"
         elif bare_metal_version >= Version("11.8"):
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6;9.0"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6;9.0+PTX"
         elif bare_metal_version >= Version("11.1"):
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6+PTX"
         elif bare_metal_version == Version("11.0"):
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0+PTX"
         else:
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5+PTX"
 
 print("\n\ntorch.__version__  = {}\n\n".format(torch.__version__))
 TORCH_MAJOR = int(torch.__version__.split(".")[0])
@@ -477,11 +477,17 @@ if "--group_norm" in sys.argv:
 
     # CUDA group norm supports from SM70
     arch_flags = []
-    # FIXME: this needs to be done more cleanly
-    for arch in [70, 75, 80, 86, 90, 100, 120]:
-        arch_flag = f"-gencode=arch=compute_{arch},code=sm_{arch}"
-        arch_flags.append(arch_flag)
-    arch_flags.append(arch_flag)
+
+    arch_flags.append("-gencode=arch=compute_70,code=sm_70")
+
+    if bare_metal_version >= Version("11.0"):
+        arch_flags.append("-gencode=arch=compute_75,code=sm_75")
+        arch_flags.append("-gencode=arch=compute_80,code=sm_80")
+    if bare_metal_version >= Version("11.8"):
+        arch_flags.append("-gencode=arch=compute_90,code=sm_90")
+    if bare_metal_version >= Version("12.8"):
+        arch_flags.append("-gencode=arch=compute_100,code=sm_100")
+        arch_flags.append("-gencode=arch=compute_120,code=sm_120")
 
     ext_modules.append(
         CUDAExtension(
@@ -500,31 +506,35 @@ if "--group_norm" in sys.argv:
     )
 
     # CUDA group norm V2 is tested on SM100
-    if bare_metal_version >= Version("12.8"):
-        arch_flags = ["-gencode=arch=compute_100,code=sm_100"]
-    else:
+    if bare_metal_version >= Version("12.4"):
         arch_flags = ["-gencode=arch=compute_90,code=compute_90"]
 
-    ext_modules.append(
-        CUDAExtension(
-            name="group_norm_v2_cuda",
-            sources=[
-                "apex/contrib/csrc/group_norm_v2/gn.cpp",
-                "apex/contrib/csrc/group_norm_v2/gn_cuda.cu",
-                "apex/contrib/csrc/group_norm_v2/gn_utils.cpp",
-            ] + glob.glob("apex/contrib/csrc/group_norm_v2/gn_cuda_inst_*.cu"),
-            extra_compile_args={
-                "cxx": ["-O2"] + version_dependent_macros,
-                "nvcc": [
-                    "-O2", "--use_fast_math", "--ftz=false",
-                    "-U__CUDA_NO_HALF_CONVERSIONS__",
-                    "-U__CUDA_NO_HALF_OPERATORS__",
-                    "-U__CUDA_NO_BFLOAT16_CONVERSIONS__",
-                    "-U__CUDA_NO_BFLOAT16_OPERATORS__",
-                ] + arch_flags + version_dependent_macros,
-            },
+        if bare_metal_version >= Version("12.8"):
+            arch_flags.extend([
+                "-gencode=arch=compute_100,code=compute_100",
+                "-gencode=arch=compute_120,code=compute_120",
+            ])
+
+        ext_modules.append(
+            CUDAExtension(
+                name="group_norm_v2_cuda",
+                sources=[
+                    "apex/contrib/csrc/group_norm_v2/gn.cpp",
+                    "apex/contrib/csrc/group_norm_v2/gn_cuda.cu",
+                    "apex/contrib/csrc/group_norm_v2/gn_utils.cpp",
+                ] + glob.glob("apex/contrib/csrc/group_norm_v2/gn_cuda_inst_*.cu"),
+                extra_compile_args={
+                    "cxx": ["-O2"] + version_dependent_macros,
+                    "nvcc": [
+                        "-O2", "--use_fast_math", "--ftz=false",
+                        "-U__CUDA_NO_HALF_CONVERSIONS__",
+                        "-U__CUDA_NO_HALF_OPERATORS__",
+                        "-U__CUDA_NO_BFLOAT16_CONVERSIONS__",
+                        "-U__CUDA_NO_BFLOAT16_OPERATORS__",
+                    ] + arch_flags + version_dependent_macros,
+                },
+            )
         )
-    )
 
 if "--index_mul_2d" in sys.argv:
     sys.argv.remove("--index_mul_2d")
