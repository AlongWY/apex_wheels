diff --git a/setup.py b/setup.py
index 4aa6616..1f861a0 100644
--- a/setup.py
+++ b/setup.py
@@ -477,11 +477,17 @@ if "--group_norm" in sys.argv:
 
     # CUDA group norm supports from SM70
     arch_flags = []
-    # FIXME: this needs to be done more cleanly
-    for arch in [70, 75, 80, 86, 90, 100, 120]:
-        arch_flag = f"-gencode=arch=compute_{arch},code=sm_{arch}"
-        arch_flags.append(arch_flag)
-    arch_flags.append(arch_flag)
+
+    arch_flags.append("-gencode=arch=compute_70,code=sm_70")
+
+    if bare_metal_version >= Version("11.0"):
+        arch_flags.append("-gencode=arch=compute_75,code=sm_75")
+        arch_flags.append("-gencode=arch=compute_80,code=sm_80")
+    if bare_metal_version >= Version("11.8"):
+        arch_flags.append("-gencode=arch=compute_90,code=sm_90")
+    if bare_metal_version >= Version("12.8"):
+        arch_flags.append("-gencode=arch=compute_100,code=sm_100")
+        arch_flags.append("-gencode=arch=compute_120,code=sm_120")
 
     ext_modules.append(
         CUDAExtension(
@@ -500,31 +506,27 @@ if "--group_norm" in sys.argv:
     )
 
     # CUDA group norm V2 is tested on SM100
-    if bare_metal_version >= Version("12.8"):
-        arch_flags = ["-gencode=arch=compute_100,code=sm_100"]
-    else:
-        arch_flags = ["-gencode=arch=compute_90,code=compute_90"]
-
-    ext_modules.append(
-        CUDAExtension(
-            name="group_norm_v2_cuda",
-            sources=[
-                "apex/contrib/csrc/group_norm_v2/gn.cpp",
-                "apex/contrib/csrc/group_norm_v2/gn_cuda.cu",
-                "apex/contrib/csrc/group_norm_v2/gn_utils.cpp",
-            ] + glob.glob("apex/contrib/csrc/group_norm_v2/gn_cuda_inst_*.cu"),
-            extra_compile_args={
-                "cxx": ["-O2"] + version_dependent_macros,
-                "nvcc": [
-                    "-O2", "--use_fast_math", "--ftz=false",
-                    "-U__CUDA_NO_HALF_CONVERSIONS__",
-                    "-U__CUDA_NO_HALF_OPERATORS__",
-                    "-U__CUDA_NO_BFLOAT16_CONVERSIONS__",
-                    "-U__CUDA_NO_BFLOAT16_OPERATORS__",
-                ] + arch_flags + version_dependent_macros,
-            },
+    if bare_metal_version >= Version("12.8"):
+        ext_modules.append(
+            CUDAExtension(
+                name="group_norm_v2_cuda",
+                sources=[
+                    "apex/contrib/csrc/group_norm_v2/gn.cpp",
+                    "apex/contrib/csrc/group_norm_v2/gn_cuda.cu",
+                    "apex/contrib/csrc/group_norm_v2/gn_utils.cpp",
+                ] + glob.glob("apex/contrib/csrc/group_norm_v2/gn_cuda_inst_*.cu"),
+                extra_compile_args={
+                    "cxx": ["-O2"] + version_dependent_macros,
+                    "nvcc": [
+                        "-O2", "--use_fast_math", "--ftz=false",
+                        "-U__CUDA_NO_HALF_CONVERSIONS__",
+                        "-U__CUDA_NO_HALF_OPERATORS__",
+                        "-U__CUDA_NO_BFLOAT16_CONVERSIONS__",
+                        "-U__CUDA_NO_BFLOAT16_OPERATORS__",
+                    ] + arch_flags + version_dependent_macros,
+                },
+            )
         )
-    )
 
 if "--index_mul_2d" in sys.argv:
     sys.argv.remove("--index_mul_2d")
